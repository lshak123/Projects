{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 처리\n",
    "\n",
    "1. Read Data\n",
    "2. 결측치 처리\n",
    "3. 데이터 형 변환\n",
    "4. 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import pandas_profiling as pp\n",
    "import gc\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# category encoding\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "# from category_encoders.one_hoe import OneHotEncoder\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/01.2.make_feature_4M_shift_data.pkl', 'rb') as f:\n",
    "    pkl_data = joblib.load(f)\n",
    "locals().update(pkl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_test = pd.read_csv(os.path.abspath(\"../input\") + '/response_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=response_test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터 분리를 고려하여 train을 TIME으로 sorting 한다.\n",
    "train.sort_values(by='TIME', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506055"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train+test feature의 train, test 구분을 위한 index 저장\n",
    "train_idx = train.shape[0]\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1506055, 89), (1355517, 89))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 train+test feature 생성\n",
    "features = pd.concat([train[features_cols],test[features_cols]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['BIRTH','SQ_R', 'A_R', 'B_R', 'C_R', 'D_R', 'F_R', 'H_R', 'T_R', 'X_R', 'ALL_R',\n",
    "                'TITLE', 'IR', 'LOI', 'CPI', 'MONTH', 'DAY', 'HOUR', \n",
    "                'RES_RATE', 'RES_RATE_3M','TYPE_RES_RATE', # 'LAST_RES_DAYS',\n",
    "                'TOT_CPI', 'AVG_CPI', 'MIN_CPI', 'MAX_CPI', 'TOT_IR', 'AVG_IR', 'MIN_IR', 'MAX_IR',\n",
    "                'TOT_LOI', 'AVG_LOI', 'MIN_LOI', 'MAX_LOI', \n",
    "                'WEEKDAY0_RES_RATE', 'WEEKDAY1_RES_RATE', 'WEEKDAY2_RES_RATE', 'WEEKDAY3_RES_RATE',\n",
    "                'WEEKDAY4_RES_RATE', 'WEEKDAY5_RES_RATE', 'WEEKDAY6_RES_RATE',\n",
    "                'HOURCLS0_RES_RATE', 'HOURCLS1_RES_RATE', 'HOURCLS2_RES_RATE', 'HOURCLS3_RES_RATE',\n",
    "                'SURVEY_HOURCLS_RES_RATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SQ4',\n",
       " 'B4',\n",
       " 'B1',\n",
       " 'B5',\n",
       " 'SQ5',\n",
       " '대상지역',\n",
       " '대상자유형',\n",
       " 'A1',\n",
       " 'TYPE',\n",
       " 'REGION',\n",
       " 'WEEKDAY',\n",
       " 'SQ8',\n",
       " 'SQ6',\n",
       " 'B3',\n",
       " 'B2',\n",
       " 'GENDER',\n",
       " 'SQ7']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = list(set(features.columns) - set(num_features))\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[cat_features+['BIRTH']] = features[cat_features+['BIRTH']].fillna(features[cat_features].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num feature 중 0으로 채울 대상\n",
    "apply_zero_features = ['SQ_R', 'A_R', 'B_R', 'C_R', 'D_R', 'F_R', 'H_R', 'T_R', 'X_R', 'ALL_R',\n",
    "                       'RES_RATE', 'RES_RATE_3M',\n",
    "                       'TOT_CPI', 'AVG_CPI', 'MIN_CPI', 'MAX_CPI', \n",
    "                       'TOT_IR', 'AVG_IR', 'MIN_IR', 'MAX_IR',\n",
    "                       'TOT_LOI', 'AVG_LOI', 'MIN_LOI', 'MAX_LOI',\n",
    "                       'WEEKDAY0_RES_RATE', 'WEEKDAY1_RES_RATE', 'WEEKDAY2_RES_RATE', 'WEEKDAY3_RES_RATE',\n",
    "                       'WEEKDAY4_RES_RATE', 'WEEKDAY5_RES_RATE', 'WEEKDAY6_RES_RATE',\n",
    "                       'HOURCLS0_RES_RATE', 'HOURCLS1_RES_RATE', 'HOURCLS2_RES_RATE', 'HOURCLS3_RES_RATE'                       \n",
    "                      ]\n",
    "features[apply_zero_features] = features[apply_zero_features].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 응답율 추이 파생변수 추가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답율 추이 변수 추가\n",
    "features['RES_RATE_TREND'] = (features['RES_RATE_3M'] - features['RES_RATE'])# / features['RES_RATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features.extend(['RES_RATE_TREND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0으로 채우는게 맞을까...유지하는 것이니...맞다고 볼 수 있을듯\n",
    "features[['RES_RATE_TREND']] = features[['RES_RATE_TREND']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['GENDER'] = features['GENDER'].astype(int)\n",
    "features['REGION'] = features['REGION'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BIRTH', 'GENDER', 'REGION', 'TYPE', 'SQ4', 'SQ5', 'SQ6', 'SQ7', 'SQ8',\n",
       "       'A1', 'B1', 'B2', 'B3', 'B4', 'B5', 'SQ_R', 'A_R', 'B_R', 'C_R', 'D_R',\n",
       "       'F_R', 'H_R', 'T_R', 'X_R', 'ALL_R', 'TITLE', 'IR', 'LOI', 'CPI',\n",
       "       '대상지역', '대상자유형', 'MONTH', 'DAY', 'HOUR', 'WEEKDAY', 'RES_RATE',\n",
       "       'RES_RATE_3M', 'TYPE_RES_RATE', 'TOT_CPI', 'AVG_CPI', 'MIN_CPI',\n",
       "       'MAX_CPI', 'TOT_IR', 'AVG_IR', 'MIN_IR', 'MAX_IR', 'TOT_LOI', 'AVG_LOI',\n",
       "       'MIN_LOI', 'MAX_LOI', 'WEEKDAY0_RES_RATE', 'WEEKDAY1_RES_RATE',\n",
       "       'WEEKDAY2_RES_RATE', 'WEEKDAY3_RES_RATE', 'WEEKDAY4_RES_RATE',\n",
       "       'WEEKDAY5_RES_RATE', 'WEEKDAY6_RES_RATE', 'HOURCLS0_RES_RATE',\n",
       "       'HOURCLS1_RES_RATE', 'HOURCLS2_RES_RATE', 'HOURCLS3_RES_RATE',\n",
       "       'SURVEY_HOURCLS_RES_RATE', 'RES_RATE_TREND'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features (feature Scaling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN 모델링에서는 StandardScaler을 주로 사용\n",
    "sacling_features_col = features.columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "features[num_features] = scaler.fit_transform(features[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 변수 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_features = features.copy()\n",
    "ohe_feature = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TargetEncoder(cols=cat_features)\n",
    "encoder.fit(te_features[cat_features].iloc[:train_idx, :], y_train)\n",
    "te_features[cat_features] = encoder.transform(te_features[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_feature =  pd.get_dummies(ohe_feature, columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ohe_feature.iloc[:train_idx, :]\n",
    "X_test = ohe_feature.iloc[train_idx:, :]\n",
    "y_train = y_train\n",
    "cat_features=cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 모델\n",
    "lgbm_clf = LGBMClassifier(random_state = 20182817,  n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.910152\ttraining's binary_logloss: 0.603552\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.913853\ttraining's binary_logloss: 0.564756\n",
      "[3]\ttraining's auc: 0.915119\ttraining's binary_logloss: 0.532752\n",
      "[4]\ttraining's auc: 0.916724\ttraining's binary_logloss: 0.505937\n",
      "[5]\ttraining's auc: 0.917621\ttraining's binary_logloss: 0.483264\n",
      "[6]\ttraining's auc: 0.918332\ttraining's binary_logloss: 0.464038\n",
      "[7]\ttraining's auc: 0.918803\ttraining's binary_logloss: 0.447441\n",
      "[8]\ttraining's auc: 0.919775\ttraining's binary_logloss: 0.432988\n",
      "[9]\ttraining's auc: 0.920366\ttraining's binary_logloss: 0.420562\n",
      "[10]\ttraining's auc: 0.921411\ttraining's binary_logloss: 0.409533\n",
      "[11]\ttraining's auc: 0.922023\ttraining's binary_logloss: 0.399907\n",
      "[12]\ttraining's auc: 0.922592\ttraining's binary_logloss: 0.39137\n",
      "[13]\ttraining's auc: 0.922924\ttraining's binary_logloss: 0.384147\n",
      "[14]\ttraining's auc: 0.923339\ttraining's binary_logloss: 0.377692\n",
      "[15]\ttraining's auc: 0.923739\ttraining's binary_logloss: 0.372008\n",
      "[16]\ttraining's auc: 0.924102\ttraining's binary_logloss: 0.366989\n",
      "[17]\ttraining's auc: 0.924722\ttraining's binary_logloss: 0.362181\n",
      "[18]\ttraining's auc: 0.925227\ttraining's binary_logloss: 0.357973\n",
      "[19]\ttraining's auc: 0.925577\ttraining's binary_logloss: 0.354367\n",
      "[20]\ttraining's auc: 0.926093\ttraining's binary_logloss: 0.351001\n",
      "[21]\ttraining's auc: 0.926414\ttraining's binary_logloss: 0.347996\n",
      "[22]\ttraining's auc: 0.926955\ttraining's binary_logloss: 0.345197\n",
      "[23]\ttraining's auc: 0.927272\ttraining's binary_logloss: 0.342819\n",
      "[24]\ttraining's auc: 0.927515\ttraining's binary_logloss: 0.340686\n",
      "[25]\ttraining's auc: 0.928014\ttraining's binary_logloss: 0.338431\n",
      "[26]\ttraining's auc: 0.928449\ttraining's binary_logloss: 0.336457\n",
      "[27]\ttraining's auc: 0.929065\ttraining's binary_logloss: 0.334298\n",
      "[28]\ttraining's auc: 0.929696\ttraining's binary_logloss: 0.332181\n",
      "[29]\ttraining's auc: 0.930151\ttraining's binary_logloss: 0.330369\n",
      "[30]\ttraining's auc: 0.930394\ttraining's binary_logloss: 0.328995\n",
      "[31]\ttraining's auc: 0.930554\ttraining's binary_logloss: 0.327869\n",
      "[32]\ttraining's auc: 0.930919\ttraining's binary_logloss: 0.32651\n",
      "[33]\ttraining's auc: 0.931175\ttraining's binary_logloss: 0.325387\n",
      "[34]\ttraining's auc: 0.931367\ttraining's binary_logloss: 0.324424\n",
      "[35]\ttraining's auc: 0.93165\ttraining's binary_logloss: 0.323345\n",
      "[36]\ttraining's auc: 0.931918\ttraining's binary_logloss: 0.322348\n",
      "[37]\ttraining's auc: 0.932234\ttraining's binary_logloss: 0.321331\n",
      "[38]\ttraining's auc: 0.932516\ttraining's binary_logloss: 0.320395\n",
      "[39]\ttraining's auc: 0.932868\ttraining's binary_logloss: 0.319353\n",
      "[40]\ttraining's auc: 0.933127\ttraining's binary_logloss: 0.318495\n",
      "[41]\ttraining's auc: 0.933413\ttraining's binary_logloss: 0.317673\n",
      "[42]\ttraining's auc: 0.933709\ttraining's binary_logloss: 0.316883\n",
      "[43]\ttraining's auc: 0.934011\ttraining's binary_logloss: 0.316014\n",
      "[44]\ttraining's auc: 0.934332\ttraining's binary_logloss: 0.315078\n",
      "[45]\ttraining's auc: 0.934552\ttraining's binary_logloss: 0.314383\n",
      "[46]\ttraining's auc: 0.934715\ttraining's binary_logloss: 0.313835\n",
      "[47]\ttraining's auc: 0.934919\ttraining's binary_logloss: 0.313226\n",
      "[48]\ttraining's auc: 0.935128\ttraining's binary_logloss: 0.312591\n",
      "[49]\ttraining's auc: 0.93534\ttraining's binary_logloss: 0.312\n",
      "[50]\ttraining's auc: 0.935473\ttraining's binary_logloss: 0.311537\n",
      "[51]\ttraining's auc: 0.935701\ttraining's binary_logloss: 0.310894\n",
      "[52]\ttraining's auc: 0.935874\ttraining's binary_logloss: 0.310393\n",
      "[53]\ttraining's auc: 0.93602\ttraining's binary_logloss: 0.309975\n",
      "[54]\ttraining's auc: 0.936185\ttraining's binary_logloss: 0.309522\n",
      "[55]\ttraining's auc: 0.9364\ttraining's binary_logloss: 0.308954\n",
      "[56]\ttraining's auc: 0.936545\ttraining's binary_logloss: 0.30851\n",
      "[57]\ttraining's auc: 0.936701\ttraining's binary_logloss: 0.308083\n",
      "[58]\ttraining's auc: 0.936941\ttraining's binary_logloss: 0.307567\n",
      "[59]\ttraining's auc: 0.937166\ttraining's binary_logloss: 0.306969\n",
      "[60]\ttraining's auc: 0.937264\ttraining's binary_logloss: 0.306665\n",
      "[61]\ttraining's auc: 0.937449\ttraining's binary_logloss: 0.306194\n",
      "[62]\ttraining's auc: 0.937672\ttraining's binary_logloss: 0.305648\n",
      "[63]\ttraining's auc: 0.937853\ttraining's binary_logloss: 0.305214\n",
      "[64]\ttraining's auc: 0.937988\ttraining's binary_logloss: 0.304856\n",
      "[65]\ttraining's auc: 0.938165\ttraining's binary_logloss: 0.304404\n",
      "[66]\ttraining's auc: 0.938371\ttraining's binary_logloss: 0.303879\n",
      "[67]\ttraining's auc: 0.938557\ttraining's binary_logloss: 0.303395\n",
      "[68]\ttraining's auc: 0.938689\ttraining's binary_logloss: 0.303027\n",
      "[69]\ttraining's auc: 0.938925\ttraining's binary_logloss: 0.302475\n",
      "[70]\ttraining's auc: 0.939059\ttraining's binary_logloss: 0.302121\n",
      "[71]\ttraining's auc: 0.939189\ttraining's binary_logloss: 0.301785\n",
      "[72]\ttraining's auc: 0.939296\ttraining's binary_logloss: 0.301488\n",
      "[73]\ttraining's auc: 0.939393\ttraining's binary_logloss: 0.30123\n",
      "[74]\ttraining's auc: 0.939576\ttraining's binary_logloss: 0.300772\n",
      "[75]\ttraining's auc: 0.939701\ttraining's binary_logloss: 0.300447\n",
      "[76]\ttraining's auc: 0.939833\ttraining's binary_logloss: 0.300134\n",
      "[77]\ttraining's auc: 0.939939\ttraining's binary_logloss: 0.299842\n",
      "[78]\ttraining's auc: 0.94005\ttraining's binary_logloss: 0.299556\n",
      "[79]\ttraining's auc: 0.940256\ttraining's binary_logloss: 0.299091\n",
      "[80]\ttraining's auc: 0.940368\ttraining's binary_logloss: 0.298771\n",
      "[81]\ttraining's auc: 0.940486\ttraining's binary_logloss: 0.298462\n",
      "[82]\ttraining's auc: 0.940645\ttraining's binary_logloss: 0.298053\n",
      "[83]\ttraining's auc: 0.940717\ttraining's binary_logloss: 0.29784\n",
      "[84]\ttraining's auc: 0.940787\ttraining's binary_logloss: 0.297634\n",
      "[85]\ttraining's auc: 0.94088\ttraining's binary_logloss: 0.297385\n",
      "[86]\ttraining's auc: 0.941021\ttraining's binary_logloss: 0.297046\n",
      "[87]\ttraining's auc: 0.941188\ttraining's binary_logloss: 0.296647\n",
      "[88]\ttraining's auc: 0.941288\ttraining's binary_logloss: 0.296357\n",
      "[89]\ttraining's auc: 0.941357\ttraining's binary_logloss: 0.296178\n",
      "[90]\ttraining's auc: 0.94141\ttraining's binary_logloss: 0.296029\n",
      "[91]\ttraining's auc: 0.94151\ttraining's binary_logloss: 0.295761\n",
      "[92]\ttraining's auc: 0.941686\ttraining's binary_logloss: 0.295356\n",
      "[93]\ttraining's auc: 0.941789\ttraining's binary_logloss: 0.295088\n",
      "[94]\ttraining's auc: 0.941889\ttraining's binary_logloss: 0.294819\n",
      "[95]\ttraining's auc: 0.941953\ttraining's binary_logloss: 0.294642\n",
      "[96]\ttraining's auc: 0.942008\ttraining's binary_logloss: 0.294498\n",
      "[97]\ttraining's auc: 0.942146\ttraining's binary_logloss: 0.294171\n",
      "[98]\ttraining's auc: 0.94223\ttraining's binary_logloss: 0.293962\n",
      "[99]\ttraining's auc: 0.942338\ttraining's binary_logloss: 0.293705\n",
      "[100]\ttraining's auc: 0.942411\ttraining's binary_logloss: 0.293511\n",
      "[101]\ttraining's auc: 0.942482\ttraining's binary_logloss: 0.293322\n",
      "[102]\ttraining's auc: 0.942559\ttraining's binary_logloss: 0.293128\n",
      "[103]\ttraining's auc: 0.942662\ttraining's binary_logloss: 0.292854\n",
      "[104]\ttraining's auc: 0.942712\ttraining's binary_logloss: 0.292715\n",
      "[105]\ttraining's auc: 0.942756\ttraining's binary_logloss: 0.292595\n",
      "[106]\ttraining's auc: 0.942937\ttraining's binary_logloss: 0.292157\n",
      "[107]\ttraining's auc: 0.943033\ttraining's binary_logloss: 0.291923\n",
      "[108]\ttraining's auc: 0.943147\ttraining's binary_logloss: 0.29163\n",
      "[109]\ttraining's auc: 0.943192\ttraining's binary_logloss: 0.291498\n",
      "[110]\ttraining's auc: 0.943271\ttraining's binary_logloss: 0.291303\n",
      "[111]\ttraining's auc: 0.94336\ttraining's binary_logloss: 0.291095\n",
      "[112]\ttraining's auc: 0.943401\ttraining's binary_logloss: 0.290981\n",
      "[113]\ttraining's auc: 0.943512\ttraining's binary_logloss: 0.290712\n",
      "[114]\ttraining's auc: 0.943591\ttraining's binary_logloss: 0.290513\n",
      "[115]\ttraining's auc: 0.943684\ttraining's binary_logloss: 0.290272\n",
      "[116]\ttraining's auc: 0.943785\ttraining's binary_logloss: 0.290027\n",
      "[117]\ttraining's auc: 0.943846\ttraining's binary_logloss: 0.289881\n",
      "[118]\ttraining's auc: 0.9439\ttraining's binary_logloss: 0.289738\n",
      "[119]\ttraining's auc: 0.943977\ttraining's binary_logloss: 0.289553\n",
      "[120]\ttraining's auc: 0.944033\ttraining's binary_logloss: 0.289403\n",
      "[121]\ttraining's auc: 0.944115\ttraining's binary_logloss: 0.289192\n",
      "[122]\ttraining's auc: 0.944188\ttraining's binary_logloss: 0.289001\n",
      "[123]\ttraining's auc: 0.944252\ttraining's binary_logloss: 0.288832\n",
      "[124]\ttraining's auc: 0.944387\ttraining's binary_logloss: 0.288495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125]\ttraining's auc: 0.944465\ttraining's binary_logloss: 0.288283\n",
      "[126]\ttraining's auc: 0.9445\ttraining's binary_logloss: 0.288192\n",
      "[127]\ttraining's auc: 0.944564\ttraining's binary_logloss: 0.288026\n",
      "[128]\ttraining's auc: 0.944618\ttraining's binary_logloss: 0.28788\n",
      "[129]\ttraining's auc: 0.944678\ttraining's binary_logloss: 0.287719\n",
      "[130]\ttraining's auc: 0.944746\ttraining's binary_logloss: 0.287551\n",
      "[131]\ttraining's auc: 0.944848\ttraining's binary_logloss: 0.287287\n",
      "[132]\ttraining's auc: 0.9449\ttraining's binary_logloss: 0.287148\n",
      "[133]\ttraining's auc: 0.945003\ttraining's binary_logloss: 0.28691\n",
      "[134]\ttraining's auc: 0.945069\ttraining's binary_logloss: 0.286753\n",
      "[135]\ttraining's auc: 0.945169\ttraining's binary_logloss: 0.286487\n",
      "[136]\ttraining's auc: 0.945217\ttraining's binary_logloss: 0.286363\n",
      "[137]\ttraining's auc: 0.945257\ttraining's binary_logloss: 0.286266\n",
      "[138]\ttraining's auc: 0.945296\ttraining's binary_logloss: 0.286166\n",
      "[139]\ttraining's auc: 0.945344\ttraining's binary_logloss: 0.286039\n",
      "[140]\ttraining's auc: 0.94539\ttraining's binary_logloss: 0.285918\n",
      "[141]\ttraining's auc: 0.945414\ttraining's binary_logloss: 0.285844\n",
      "[142]\ttraining's auc: 0.945463\ttraining's binary_logloss: 0.285706\n",
      "[143]\ttraining's auc: 0.9455\ttraining's binary_logloss: 0.285612\n",
      "[144]\ttraining's auc: 0.945538\ttraining's binary_logloss: 0.285495\n",
      "[145]\ttraining's auc: 0.945583\ttraining's binary_logloss: 0.285376\n",
      "[146]\ttraining's auc: 0.945617\ttraining's binary_logloss: 0.285299\n",
      "[147]\ttraining's auc: 0.945685\ttraining's binary_logloss: 0.285123\n",
      "[148]\ttraining's auc: 0.945792\ttraining's binary_logloss: 0.284844\n",
      "[149]\ttraining's auc: 0.945866\ttraining's binary_logloss: 0.28464\n",
      "[150]\ttraining's auc: 0.945896\ttraining's binary_logloss: 0.284559\n",
      "[151]\ttraining's auc: 0.945936\ttraining's binary_logloss: 0.284456\n",
      "[152]\ttraining's auc: 0.946003\ttraining's binary_logloss: 0.284285\n",
      "[153]\ttraining's auc: 0.946036\ttraining's binary_logloss: 0.284204\n",
      "[154]\ttraining's auc: 0.946109\ttraining's binary_logloss: 0.284013\n",
      "[155]\ttraining's auc: 0.946152\ttraining's binary_logloss: 0.283894\n",
      "[156]\ttraining's auc: 0.946178\ttraining's binary_logloss: 0.283825\n",
      "[157]\ttraining's auc: 0.946241\ttraining's binary_logloss: 0.283643\n",
      "[158]\ttraining's auc: 0.946271\ttraining's binary_logloss: 0.283567\n",
      "[159]\ttraining's auc: 0.9463\ttraining's binary_logloss: 0.283479\n",
      "[160]\ttraining's auc: 0.946337\ttraining's binary_logloss: 0.283386\n",
      "[161]\ttraining's auc: 0.946368\ttraining's binary_logloss: 0.283303\n",
      "[162]\ttraining's auc: 0.946395\ttraining's binary_logloss: 0.283236\n",
      "[163]\ttraining's auc: 0.946424\ttraining's binary_logloss: 0.283166\n",
      "[164]\ttraining's auc: 0.946482\ttraining's binary_logloss: 0.283033\n",
      "[165]\ttraining's auc: 0.946513\ttraining's binary_logloss: 0.282961\n",
      "[166]\ttraining's auc: 0.946587\ttraining's binary_logloss: 0.282785\n",
      "[167]\ttraining's auc: 0.946638\ttraining's binary_logloss: 0.282647\n",
      "[168]\ttraining's auc: 0.946664\ttraining's binary_logloss: 0.282576\n",
      "[169]\ttraining's auc: 0.946701\ttraining's binary_logloss: 0.282475\n",
      "[170]\ttraining's auc: 0.946749\ttraining's binary_logloss: 0.282349\n",
      "[171]\ttraining's auc: 0.946792\ttraining's binary_logloss: 0.282233\n",
      "[172]\ttraining's auc: 0.946823\ttraining's binary_logloss: 0.282154\n",
      "[173]\ttraining's auc: 0.946878\ttraining's binary_logloss: 0.282016\n",
      "[174]\ttraining's auc: 0.946952\ttraining's binary_logloss: 0.281836\n",
      "[175]\ttraining's auc: 0.947\ttraining's binary_logloss: 0.281711\n",
      "[176]\ttraining's auc: 0.947025\ttraining's binary_logloss: 0.281644\n",
      "[177]\ttraining's auc: 0.947055\ttraining's binary_logloss: 0.281562\n",
      "[178]\ttraining's auc: 0.947101\ttraining's binary_logloss: 0.281451\n",
      "[179]\ttraining's auc: 0.947163\ttraining's binary_logloss: 0.281299\n",
      "[180]\ttraining's auc: 0.947198\ttraining's binary_logloss: 0.2812\n",
      "[181]\ttraining's auc: 0.947231\ttraining's binary_logloss: 0.281111\n",
      "[182]\ttraining's auc: 0.94726\ttraining's binary_logloss: 0.281046\n",
      "[183]\ttraining's auc: 0.947286\ttraining's binary_logloss: 0.280978\n",
      "[184]\ttraining's auc: 0.94733\ttraining's binary_logloss: 0.28087\n",
      "[185]\ttraining's auc: 0.947354\ttraining's binary_logloss: 0.280801\n",
      "[186]\ttraining's auc: 0.947383\ttraining's binary_logloss: 0.280707\n",
      "[187]\ttraining's auc: 0.947413\ttraining's binary_logloss: 0.280633\n",
      "[188]\ttraining's auc: 0.947469\ttraining's binary_logloss: 0.280474\n",
      "[189]\ttraining's auc: 0.947505\ttraining's binary_logloss: 0.280389\n",
      "[190]\ttraining's auc: 0.947531\ttraining's binary_logloss: 0.280321\n",
      "[191]\ttraining's auc: 0.947563\ttraining's binary_logloss: 0.280228\n",
      "[192]\ttraining's auc: 0.947602\ttraining's binary_logloss: 0.280138\n",
      "[193]\ttraining's auc: 0.947627\ttraining's binary_logloss: 0.280076\n",
      "[194]\ttraining's auc: 0.94765\ttraining's binary_logloss: 0.280021\n",
      "[195]\ttraining's auc: 0.94768\ttraining's binary_logloss: 0.279937\n",
      "[196]\ttraining's auc: 0.947703\ttraining's binary_logloss: 0.279871\n",
      "[197]\ttraining's auc: 0.947756\ttraining's binary_logloss: 0.279733\n",
      "[198]\ttraining's auc: 0.947804\ttraining's binary_logloss: 0.27962\n",
      "[199]\ttraining's auc: 0.947868\ttraining's binary_logloss: 0.279457\n",
      "[200]\ttraining's auc: 0.947892\ttraining's binary_logloss: 0.279387\n",
      "[201]\ttraining's auc: 0.947907\ttraining's binary_logloss: 0.27985\n",
      "[202]\ttraining's auc: 0.947954\ttraining's binary_logloss: 0.279218\n",
      "[203]\ttraining's auc: 0.947983\ttraining's binary_logloss: 0.279148\n",
      "[204]\ttraining's auc: 0.948014\ttraining's binary_logloss: 0.279068\n",
      "[205]\ttraining's auc: 0.948042\ttraining's binary_logloss: 0.278981\n",
      "[206]\ttraining's auc: 0.948068\ttraining's binary_logloss: 0.278908\n",
      "[207]\ttraining's auc: 0.948099\ttraining's binary_logloss: 0.278833\n",
      "[208]\ttraining's auc: 0.948125\ttraining's binary_logloss: 0.278761\n",
      "[209]\ttraining's auc: 0.948148\ttraining's binary_logloss: 0.278696\n",
      "[210]\ttraining's auc: 0.948172\ttraining's binary_logloss: 0.278632\n",
      "[211]\ttraining's auc: 0.948234\ttraining's binary_logloss: 0.278475\n",
      "[212]\ttraining's auc: 0.948293\ttraining's binary_logloss: 0.278313\n",
      "[213]\ttraining's auc: 0.948317\ttraining's binary_logloss: 0.278235\n",
      "[214]\ttraining's auc: 0.948363\ttraining's binary_logloss: 0.278102\n",
      "[215]\ttraining's auc: 0.948388\ttraining's binary_logloss: 0.278033\n",
      "[216]\ttraining's auc: 0.948406\ttraining's binary_logloss: 0.277988\n",
      "[217]\ttraining's auc: 0.948421\ttraining's binary_logloss: 0.277946\n",
      "[218]\ttraining's auc: 0.948475\ttraining's binary_logloss: 0.277814\n",
      "[219]\ttraining's auc: 0.9485\ttraining's binary_logloss: 0.277752\n",
      "[220]\ttraining's auc: 0.948523\ttraining's binary_logloss: 0.277691\n",
      "[221]\ttraining's auc: 0.948553\ttraining's binary_logloss: 0.277612\n",
      "[222]\ttraining's auc: 0.948592\ttraining's binary_logloss: 0.277517\n",
      "[223]\ttraining's auc: 0.948619\ttraining's binary_logloss: 0.277452\n",
      "[224]\ttraining's auc: 0.94866\ttraining's binary_logloss: 0.277356\n",
      "[225]\ttraining's auc: 0.948723\ttraining's binary_logloss: 0.277211\n",
      "[226]\ttraining's auc: 0.948739\ttraining's binary_logloss: 0.277169\n",
      "[227]\ttraining's auc: 0.948756\ttraining's binary_logloss: 0.277121\n",
      "[228]\ttraining's auc: 0.94879\ttraining's binary_logloss: 0.277035\n",
      "[229]\ttraining's auc: 0.948811\ttraining's binary_logloss: 0.276969\n",
      "[230]\ttraining's auc: 0.948837\ttraining's binary_logloss: 0.276907\n",
      "[231]\ttraining's auc: 0.948879\ttraining's binary_logloss: 0.276795\n",
      "[232]\ttraining's auc: 0.948901\ttraining's binary_logloss: 0.276735\n",
      "[233]\ttraining's auc: 0.948919\ttraining's binary_logloss: 0.276685\n",
      "[234]\ttraining's auc: 0.948939\ttraining's binary_logloss: 0.276624\n",
      "[235]\ttraining's auc: 0.948962\ttraining's binary_logloss: 0.276568\n",
      "[236]\ttraining's auc: 0.948984\ttraining's binary_logloss: 0.276515\n",
      "[237]\ttraining's auc: 0.949028\ttraining's binary_logloss: 0.276405\n",
      "[238]\ttraining's auc: 0.94905\ttraining's binary_logloss: 0.276339\n",
      "[239]\ttraining's auc: 0.94907\ttraining's binary_logloss: 0.276283\n",
      "[240]\ttraining's auc: 0.949093\ttraining's binary_logloss: 0.276232\n",
      "[241]\ttraining's auc: 0.949123\ttraining's binary_logloss: 0.276149\n",
      "[242]\ttraining's auc: 0.949167\ttraining's binary_logloss: 0.276044\n",
      "[243]\ttraining's auc: 0.949221\ttraining's binary_logloss: 0.275905\n",
      "[244]\ttraining's auc: 0.949242\ttraining's binary_logloss: 0.275835\n",
      "[245]\ttraining's auc: 0.94926\ttraining's binary_logloss: 0.275789\n",
      "[246]\ttraining's auc: 0.949277\ttraining's binary_logloss: 0.275738\n",
      "[247]\ttraining's auc: 0.949299\ttraining's binary_logloss: 0.275687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248]\ttraining's auc: 0.94934\ttraining's binary_logloss: 0.275574\n",
      "[249]\ttraining's auc: 0.949366\ttraining's binary_logloss: 0.275492\n",
      "[250]\ttraining's auc: 0.949395\ttraining's binary_logloss: 0.275424\n",
      "[251]\ttraining's auc: 0.949418\ttraining's binary_logloss: 0.275372\n",
      "[252]\ttraining's auc: 0.949453\ttraining's binary_logloss: 0.275284\n",
      "[253]\ttraining's auc: 0.94947\ttraining's binary_logloss: 0.275246\n",
      "[254]\ttraining's auc: 0.949494\ttraining's binary_logloss: 0.275188\n",
      "[255]\ttraining's auc: 0.949513\ttraining's binary_logloss: 0.275139\n",
      "[256]\ttraining's auc: 0.949526\ttraining's binary_logloss: 0.275109\n",
      "[257]\ttraining's auc: 0.94957\ttraining's binary_logloss: 0.274999\n",
      "[258]\ttraining's auc: 0.949594\ttraining's binary_logloss: 0.274934\n",
      "[259]\ttraining's auc: 0.949637\ttraining's binary_logloss: 0.274825\n",
      "[260]\ttraining's auc: 0.949652\ttraining's binary_logloss: 0.274785\n",
      "[261]\ttraining's auc: 0.949667\ttraining's binary_logloss: 0.274745\n",
      "[262]\ttraining's auc: 0.94969\ttraining's binary_logloss: 0.274682\n",
      "[263]\ttraining's auc: 0.949723\ttraining's binary_logloss: 0.274601\n",
      "[264]\ttraining's auc: 0.949748\ttraining's binary_logloss: 0.274523\n",
      "[265]\ttraining's auc: 0.949765\ttraining's binary_logloss: 0.274482\n",
      "[266]\ttraining's auc: 0.949791\ttraining's binary_logloss: 0.27442\n",
      "[267]\ttraining's auc: 0.949802\ttraining's binary_logloss: 0.27439\n",
      "[268]\ttraining's auc: 0.949818\ttraining's binary_logloss: 0.274352\n",
      "[269]\ttraining's auc: 0.94986\ttraining's binary_logloss: 0.274242\n",
      "[270]\ttraining's auc: 0.949877\ttraining's binary_logloss: 0.274183\n",
      "[271]\ttraining's auc: 0.949897\ttraining's binary_logloss: 0.274133\n",
      "[272]\ttraining's auc: 0.949917\ttraining's binary_logloss: 0.27408\n",
      "[273]\ttraining's auc: 0.949945\ttraining's binary_logloss: 0.274\n",
      "[274]\ttraining's auc: 0.949988\ttraining's binary_logloss: 0.273894\n",
      "[275]\ttraining's auc: 0.950007\ttraining's binary_logloss: 0.27384\n",
      "[276]\ttraining's auc: 0.950024\ttraining's binary_logloss: 0.273784\n",
      "[277]\ttraining's auc: 0.950044\ttraining's binary_logloss: 0.273728\n",
      "[278]\ttraining's auc: 0.950061\ttraining's binary_logloss: 0.273687\n",
      "[279]\ttraining's auc: 0.950076\ttraining's binary_logloss: 0.273648\n",
      "[280]\ttraining's auc: 0.950094\ttraining's binary_logloss: 0.273604\n",
      "[281]\ttraining's auc: 0.950107\ttraining's binary_logloss: 0.273572\n",
      "[282]\ttraining's auc: 0.950122\ttraining's binary_logloss: 0.273539\n",
      "[283]\ttraining's auc: 0.950166\ttraining's binary_logloss: 0.273423\n",
      "[284]\ttraining's auc: 0.950198\ttraining's binary_logloss: 0.273348\n",
      "[285]\ttraining's auc: 0.950233\ttraining's binary_logloss: 0.273247\n",
      "[286]\ttraining's auc: 0.95025\ttraining's binary_logloss: 0.273197\n",
      "[287]\ttraining's auc: 0.950265\ttraining's binary_logloss: 0.273151\n",
      "[288]\ttraining's auc: 0.950303\ttraining's binary_logloss: 0.273059\n",
      "[289]\ttraining's auc: 0.950344\ttraining's binary_logloss: 0.272957\n",
      "[290]\ttraining's auc: 0.950363\ttraining's binary_logloss: 0.272897\n",
      "[291]\ttraining's auc: 0.950387\ttraining's binary_logloss: 0.272829\n",
      "[292]\ttraining's auc: 0.950411\ttraining's binary_logloss: 0.272778\n",
      "[293]\ttraining's auc: 0.950428\ttraining's binary_logloss: 0.272718\n",
      "[294]\ttraining's auc: 0.95044\ttraining's binary_logloss: 0.272686\n",
      "[295]\ttraining's auc: 0.95047\ttraining's binary_logloss: 0.272603\n",
      "[296]\ttraining's auc: 0.950484\ttraining's binary_logloss: 0.27256\n",
      "[297]\ttraining's auc: 0.950503\ttraining's binary_logloss: 0.272506\n",
      "[298]\ttraining's auc: 0.950517\ttraining's binary_logloss: 0.272473\n",
      "[299]\ttraining's auc: 0.95057\ttraining's binary_logloss: 0.272341\n",
      "[300]\ttraining's auc: 0.950586\ttraining's binary_logloss: 0.2723\n",
      "[301]\ttraining's auc: 0.950613\ttraining's binary_logloss: 0.272226\n",
      "[302]\ttraining's auc: 0.95063\ttraining's binary_logloss: 0.272184\n",
      "[303]\ttraining's auc: 0.950649\ttraining's binary_logloss: 0.272132\n",
      "[304]\ttraining's auc: 0.950665\ttraining's binary_logloss: 0.272089\n",
      "[305]\ttraining's auc: 0.950704\ttraining's binary_logloss: 0.271992\n",
      "[306]\ttraining's auc: 0.950727\ttraining's binary_logloss: 0.271927\n",
      "[307]\ttraining's auc: 0.950767\ttraining's binary_logloss: 0.271819\n",
      "[308]\ttraining's auc: 0.950802\ttraining's binary_logloss: 0.271727\n",
      "[309]\ttraining's auc: 0.950844\ttraining's binary_logloss: 0.271611\n",
      "[310]\ttraining's auc: 0.950854\ttraining's binary_logloss: 0.271588\n",
      "[311]\ttraining's auc: 0.950864\ttraining's binary_logloss: 0.271552\n",
      "[312]\ttraining's auc: 0.950888\ttraining's binary_logloss: 0.271485\n",
      "[313]\ttraining's auc: 0.950922\ttraining's binary_logloss: 0.271398\n",
      "[314]\ttraining's auc: 0.95097\ttraining's binary_logloss: 0.271268\n",
      "[315]\ttraining's auc: 0.951003\ttraining's binary_logloss: 0.27118\n",
      "[316]\ttraining's auc: 0.951022\ttraining's binary_logloss: 0.271129\n",
      "[317]\ttraining's auc: 0.951075\ttraining's binary_logloss: 0.271\n",
      "[318]\ttraining's auc: 0.951084\ttraining's binary_logloss: 0.270975\n",
      "[319]\ttraining's auc: 0.951104\ttraining's binary_logloss: 0.270927\n",
      "[320]\ttraining's auc: 0.951128\ttraining's binary_logloss: 0.270867\n",
      "[321]\ttraining's auc: 0.951193\ttraining's binary_logloss: 0.270706\n",
      "[322]\ttraining's auc: 0.95121\ttraining's binary_logloss: 0.270652\n",
      "[323]\ttraining's auc: 0.951221\ttraining's binary_logloss: 0.270618\n",
      "[324]\ttraining's auc: 0.951249\ttraining's binary_logloss: 0.270526\n",
      "[325]\ttraining's auc: 0.951259\ttraining's binary_logloss: 0.270497\n",
      "[326]\ttraining's auc: 0.951307\ttraining's binary_logloss: 0.270369\n",
      "[327]\ttraining's auc: 0.951321\ttraining's binary_logloss: 0.270322\n",
      "[328]\ttraining's auc: 0.951355\ttraining's binary_logloss: 0.270231\n",
      "[329]\ttraining's auc: 0.951364\ttraining's binary_logloss: 0.270205\n",
      "[330]\ttraining's auc: 0.95138\ttraining's binary_logloss: 0.270159\n",
      "[331]\ttraining's auc: 0.951399\ttraining's binary_logloss: 0.270114\n",
      "[332]\ttraining's auc: 0.951444\ttraining's binary_logloss: 0.269997\n",
      "[333]\ttraining's auc: 0.951466\ttraining's binary_logloss: 0.269941\n",
      "[334]\ttraining's auc: 0.95149\ttraining's binary_logloss: 0.269881\n",
      "[335]\ttraining's auc: 0.951506\ttraining's binary_logloss: 0.26984\n",
      "[336]\ttraining's auc: 0.951536\ttraining's binary_logloss: 0.269763\n",
      "[337]\ttraining's auc: 0.951558\ttraining's binary_logloss: 0.269696\n",
      "[338]\ttraining's auc: 0.951574\ttraining's binary_logloss: 0.269646\n",
      "[339]\ttraining's auc: 0.95159\ttraining's binary_logloss: 0.269608\n",
      "[340]\ttraining's auc: 0.951605\ttraining's binary_logloss: 0.269565\n",
      "[341]\ttraining's auc: 0.951619\ttraining's binary_logloss: 0.269529\n",
      "[342]\ttraining's auc: 0.951633\ttraining's binary_logloss: 0.269482\n",
      "[343]\ttraining's auc: 0.951656\ttraining's binary_logloss: 0.269415\n",
      "[344]\ttraining's auc: 0.951684\ttraining's binary_logloss: 0.269344\n",
      "[345]\ttraining's auc: 0.951702\ttraining's binary_logloss: 0.269298\n",
      "[346]\ttraining's auc: 0.951717\ttraining's binary_logloss: 0.269262\n",
      "[347]\ttraining's auc: 0.951728\ttraining's binary_logloss: 0.269226\n",
      "[348]\ttraining's auc: 0.951742\ttraining's binary_logloss: 0.269187\n",
      "[349]\ttraining's auc: 0.951767\ttraining's binary_logloss: 0.269121\n",
      "[350]\ttraining's auc: 0.95178\ttraining's binary_logloss: 0.26909\n",
      "[351]\ttraining's auc: 0.951795\ttraining's binary_logloss: 0.269054\n",
      "[352]\ttraining's auc: 0.951824\ttraining's binary_logloss: 0.268971\n",
      "[353]\ttraining's auc: 0.951848\ttraining's binary_logloss: 0.268912\n",
      "[354]\ttraining's auc: 0.951866\ttraining's binary_logloss: 0.26887\n",
      "[355]\ttraining's auc: 0.951887\ttraining's binary_logloss: 0.268815\n",
      "[356]\ttraining's auc: 0.951898\ttraining's binary_logloss: 0.268788\n",
      "[357]\ttraining's auc: 0.951909\ttraining's binary_logloss: 0.268762\n",
      "[358]\ttraining's auc: 0.951921\ttraining's binary_logloss: 0.268731\n",
      "[359]\ttraining's auc: 0.951934\ttraining's binary_logloss: 0.268685\n",
      "[360]\ttraining's auc: 0.951952\ttraining's binary_logloss: 0.268638\n",
      "[361]\ttraining's auc: 0.95195\ttraining's binary_logloss: 0.268944\n",
      "[362]\ttraining's auc: 0.951972\ttraining's binary_logloss: 0.268603\n",
      "[363]\ttraining's auc: 0.951986\ttraining's binary_logloss: 0.268556\n",
      "[364]\ttraining's auc: 0.952007\ttraining's binary_logloss: 0.268498\n",
      "[365]\ttraining's auc: 0.952023\ttraining's binary_logloss: 0.268451\n",
      "[366]\ttraining's auc: 0.952034\ttraining's binary_logloss: 0.268426\n",
      "[367]\ttraining's auc: 0.952048\ttraining's binary_logloss: 0.268391\n",
      "[368]\ttraining's auc: 0.952066\ttraining's binary_logloss: 0.268335\n",
      "[369]\ttraining's auc: 0.952098\ttraining's binary_logloss: 0.268247\n",
      "[370]\ttraining's auc: 0.95212\ttraining's binary_logloss: 0.268192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[371]\ttraining's auc: 0.952136\ttraining's binary_logloss: 0.268155\n",
      "[372]\ttraining's auc: 0.952144\ttraining's binary_logloss: 0.268133\n",
      "[373]\ttraining's auc: 0.952157\ttraining's binary_logloss: 0.2681\n",
      "[374]\ttraining's auc: 0.952192\ttraining's binary_logloss: 0.268008\n",
      "[375]\ttraining's auc: 0.952208\ttraining's binary_logloss: 0.26796\n",
      "[376]\ttraining's auc: 0.952215\ttraining's binary_logloss: 0.267938\n",
      "[377]\ttraining's auc: 0.952225\ttraining's binary_logloss: 0.267909\n",
      "[378]\ttraining's auc: 0.952239\ttraining's binary_logloss: 0.26787\n",
      "[379]\ttraining's auc: 0.952257\ttraining's binary_logloss: 0.267817\n",
      "[380]\ttraining's auc: 0.952271\ttraining's binary_logloss: 0.267772\n",
      "[381]\ttraining's auc: 0.952285\ttraining's binary_logloss: 0.267735\n",
      "[382]\ttraining's auc: 0.952303\ttraining's binary_logloss: 0.267685\n",
      "[383]\ttraining's auc: 0.952321\ttraining's binary_logloss: 0.267633\n",
      "[384]\ttraining's auc: 0.952371\ttraining's binary_logloss: 0.2675\n",
      "[385]\ttraining's auc: 0.952381\ttraining's binary_logloss: 0.267463\n",
      "[386]\ttraining's auc: 0.952389\ttraining's binary_logloss: 0.267444\n",
      "[387]\ttraining's auc: 0.95241\ttraining's binary_logloss: 0.267397\n",
      "[388]\ttraining's auc: 0.952419\ttraining's binary_logloss: 0.267376\n",
      "[389]\ttraining's auc: 0.95243\ttraining's binary_logloss: 0.267337\n",
      "[390]\ttraining's auc: 0.95244\ttraining's binary_logloss: 0.267312\n",
      "[391]\ttraining's auc: 0.952456\ttraining's binary_logloss: 0.267274\n",
      "[392]\ttraining's auc: 0.952496\ttraining's binary_logloss: 0.267173\n",
      "[393]\ttraining's auc: 0.952509\ttraining's binary_logloss: 0.267135\n",
      "[394]\ttraining's auc: 0.95253\ttraining's binary_logloss: 0.267078\n",
      "[395]\ttraining's auc: 0.952538\ttraining's binary_logloss: 0.267057\n",
      "[396]\ttraining's auc: 0.952549\ttraining's binary_logloss: 0.267025\n",
      "[397]\ttraining's auc: 0.952563\ttraining's binary_logloss: 0.266994\n",
      "[398]\ttraining's auc: 0.952588\ttraining's binary_logloss: 0.266928\n",
      "[399]\ttraining's auc: 0.952604\ttraining's binary_logloss: 0.266882\n",
      "[400]\ttraining's auc: 0.952626\ttraining's binary_logloss: 0.266829\n",
      "[401]\ttraining's auc: 0.952634\ttraining's binary_logloss: 0.266805\n",
      "[402]\ttraining's auc: 0.952651\ttraining's binary_logloss: 0.266762\n",
      "[403]\ttraining's auc: 0.952662\ttraining's binary_logloss: 0.266731\n",
      "[404]\ttraining's auc: 0.952676\ttraining's binary_logloss: 0.266693\n",
      "[405]\ttraining's auc: 0.952687\ttraining's binary_logloss: 0.266664\n",
      "[406]\ttraining's auc: 0.952713\ttraining's binary_logloss: 0.266597\n",
      "[407]\ttraining's auc: 0.952731\ttraining's binary_logloss: 0.266543\n",
      "[408]\ttraining's auc: 0.95274\ttraining's binary_logloss: 0.266517\n",
      "[409]\ttraining's auc: 0.952755\ttraining's binary_logloss: 0.26648\n",
      "[410]\ttraining's auc: 0.952807\ttraining's binary_logloss: 0.266351\n",
      "[411]\ttraining's auc: 0.952814\ttraining's binary_logloss: 0.26633\n",
      "[412]\ttraining's auc: 0.952843\ttraining's binary_logloss: 0.266257\n",
      "[413]\ttraining's auc: 0.952856\ttraining's binary_logloss: 0.266211\n",
      "[414]\ttraining's auc: 0.952884\ttraining's binary_logloss: 0.266136\n",
      "[415]\ttraining's auc: 0.952905\ttraining's binary_logloss: 0.266083\n",
      "[416]\ttraining's auc: 0.952934\ttraining's binary_logloss: 0.265998\n",
      "[417]\ttraining's auc: 0.952952\ttraining's binary_logloss: 0.265946\n",
      "[418]\ttraining's auc: 0.952967\ttraining's binary_logloss: 0.265907\n",
      "[419]\ttraining's auc: 0.952984\ttraining's binary_logloss: 0.265868\n",
      "[420]\ttraining's auc: 0.953\ttraining's binary_logloss: 0.265814\n",
      "[421]\ttraining's auc: 0.953013\ttraining's binary_logloss: 0.265775\n",
      "[422]\ttraining's auc: 0.953027\ttraining's binary_logloss: 0.265745\n",
      "[423]\ttraining's auc: 0.953042\ttraining's binary_logloss: 0.265707\n",
      "[424]\ttraining's auc: 0.95306\ttraining's binary_logloss: 0.265663\n",
      "[425]\ttraining's auc: 0.953072\ttraining's binary_logloss: 0.265624\n",
      "[426]\ttraining's auc: 0.95311\ttraining's binary_logloss: 0.265519\n",
      "[427]\ttraining's auc: 0.953148\ttraining's binary_logloss: 0.265419\n",
      "[428]\ttraining's auc: 0.953157\ttraining's binary_logloss: 0.265393\n",
      "[429]\ttraining's auc: 0.953172\ttraining's binary_logloss: 0.265353\n",
      "[430]\ttraining's auc: 0.953188\ttraining's binary_logloss: 0.265315\n",
      "[431]\ttraining's auc: 0.953215\ttraining's binary_logloss: 0.26523\n",
      "[432]\ttraining's auc: 0.95323\ttraining's binary_logloss: 0.265188\n",
      "[433]\ttraining's auc: 0.953261\ttraining's binary_logloss: 0.265101\n",
      "[434]\ttraining's auc: 0.953279\ttraining's binary_logloss: 0.265063\n",
      "[435]\ttraining's auc: 0.953299\ttraining's binary_logloss: 0.265003\n",
      "[436]\ttraining's auc: 0.953311\ttraining's binary_logloss: 0.264969\n",
      "[437]\ttraining's auc: 0.953325\ttraining's binary_logloss: 0.264928\n",
      "[438]\ttraining's auc: 0.953342\ttraining's binary_logloss: 0.264875\n",
      "[439]\ttraining's auc: 0.953354\ttraining's binary_logloss: 0.264844\n",
      "[440]\ttraining's auc: 0.953377\ttraining's binary_logloss: 0.264779\n",
      "[441]\ttraining's auc: 0.953387\ttraining's binary_logloss: 0.264755\n",
      "[442]\ttraining's auc: 0.953408\ttraining's binary_logloss: 0.264693\n",
      "[443]\ttraining's auc: 0.953426\ttraining's binary_logloss: 0.264654\n",
      "[444]\ttraining's auc: 0.953443\ttraining's binary_logloss: 0.264602\n",
      "[445]\ttraining's auc: 0.953449\ttraining's binary_logloss: 0.264586\n",
      "[446]\ttraining's auc: 0.953464\ttraining's binary_logloss: 0.264548\n",
      "[447]\ttraining's auc: 0.953499\ttraining's binary_logloss: 0.26444\n",
      "[448]\ttraining's auc: 0.953525\ttraining's binary_logloss: 0.264365\n",
      "[449]\ttraining's auc: 0.953539\ttraining's binary_logloss: 0.264325\n",
      "[450]\ttraining's auc: 0.95357\ttraining's binary_logloss: 0.264229\n",
      "[451]\ttraining's auc: 0.953583\ttraining's binary_logloss: 0.264194\n",
      "[452]\ttraining's auc: 0.9536\ttraining's binary_logloss: 0.264141\n",
      "[453]\ttraining's auc: 0.953612\ttraining's binary_logloss: 0.264106\n",
      "[454]\ttraining's auc: 0.953642\ttraining's binary_logloss: 0.264014\n",
      "[455]\ttraining's auc: 0.953663\ttraining's binary_logloss: 0.263956\n",
      "[456]\ttraining's auc: 0.953676\ttraining's binary_logloss: 0.263912\n",
      "[457]\ttraining's auc: 0.953695\ttraining's binary_logloss: 0.263858\n",
      "[458]\ttraining's auc: 0.953712\ttraining's binary_logloss: 0.26382\n",
      "[459]\ttraining's auc: 0.953725\ttraining's binary_logloss: 0.263782\n",
      "[460]\ttraining's auc: 0.953746\ttraining's binary_logloss: 0.263717\n",
      "[461]\ttraining's auc: 0.95376\ttraining's binary_logloss: 0.263677\n",
      "[462]\ttraining's auc: 0.953769\ttraining's binary_logloss: 0.263649\n",
      "[463]\ttraining's auc: 0.953784\ttraining's binary_logloss: 0.263608\n",
      "[464]\ttraining's auc: 0.953795\ttraining's binary_logloss: 0.26358\n",
      "[465]\ttraining's auc: 0.953807\ttraining's binary_logloss: 0.263539\n",
      "[466]\ttraining's auc: 0.953818\ttraining's binary_logloss: 0.263514\n",
      "[467]\ttraining's auc: 0.953829\ttraining's binary_logloss: 0.263487\n",
      "[468]\ttraining's auc: 0.953842\ttraining's binary_logloss: 0.263457\n",
      "[469]\ttraining's auc: 0.953853\ttraining's binary_logloss: 0.263425\n",
      "[470]\ttraining's auc: 0.953867\ttraining's binary_logloss: 0.263394\n",
      "[471]\ttraining's auc: 0.953872\ttraining's binary_logloss: 0.263382\n",
      "[472]\ttraining's auc: 0.953948\ttraining's binary_logloss: 0.263209\n",
      "[473]\ttraining's auc: 0.953961\ttraining's binary_logloss: 0.263179\n",
      "[474]\ttraining's auc: 0.953978\ttraining's binary_logloss: 0.263128\n",
      "[475]\ttraining's auc: 0.953987\ttraining's binary_logloss: 0.263107\n",
      "[476]\ttraining's auc: 0.953994\ttraining's binary_logloss: 0.263089\n",
      "[477]\ttraining's auc: 0.954001\ttraining's binary_logloss: 0.263071\n",
      "[478]\ttraining's auc: 0.95403\ttraining's binary_logloss: 0.262993\n",
      "[479]\ttraining's auc: 0.954045\ttraining's binary_logloss: 0.262956\n",
      "[480]\ttraining's auc: 0.954069\ttraining's binary_logloss: 0.262882\n",
      "[481]\ttraining's auc: 0.954095\ttraining's binary_logloss: 0.262819\n",
      "[482]\ttraining's auc: 0.954109\ttraining's binary_logloss: 0.262769\n",
      "[483]\ttraining's auc: 0.954135\ttraining's binary_logloss: 0.262695\n",
      "[484]\ttraining's auc: 0.954148\ttraining's binary_logloss: 0.262659\n",
      "[485]\ttraining's auc: 0.954158\ttraining's binary_logloss: 0.262623\n",
      "[486]\ttraining's auc: 0.954167\ttraining's binary_logloss: 0.2626\n",
      "[487]\ttraining's auc: 0.954186\ttraining's binary_logloss: 0.262548\n",
      "[488]\ttraining's auc: 0.954196\ttraining's binary_logloss: 0.262522\n",
      "[489]\ttraining's auc: 0.954204\ttraining's binary_logloss: 0.262495\n",
      "[490]\ttraining's auc: 0.954216\ttraining's binary_logloss: 0.262467\n",
      "[491]\ttraining's auc: 0.954224\ttraining's binary_logloss: 0.262447\n",
      "[492]\ttraining's auc: 0.954236\ttraining's binary_logloss: 0.262414\n",
      "[493]\ttraining's auc: 0.954257\ttraining's binary_logloss: 0.262356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[494]\ttraining's auc: 0.954269\ttraining's binary_logloss: 0.262323\n",
      "[495]\ttraining's auc: 0.954275\ttraining's binary_logloss: 0.262305\n",
      "[496]\ttraining's auc: 0.954284\ttraining's binary_logloss: 0.262278\n",
      "[497]\ttraining's auc: 0.954304\ttraining's binary_logloss: 0.262218\n",
      "[498]\ttraining's auc: 0.95432\ttraining's binary_logloss: 0.262172\n",
      "[499]\ttraining's auc: 0.954337\ttraining's binary_logloss: 0.262126\n",
      "[500]\ttraining's auc: 0.954351\ttraining's binary_logloss: 0.262087\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's auc: 0.954351\ttraining's binary_logloss: 0.262087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=20182817, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric = ['auc','logloss'], \n",
    "        verbose=True, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'ID':ID, 'STATUS': lgbm_clf.predict_proba(X_test)[:,1]}).to_csv(os.path.abspath(\"./e_submission\") + \"/new_lgbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
